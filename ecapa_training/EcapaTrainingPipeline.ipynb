{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e922b7-cb57-4773-a5cc-82b735e06d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-27 14:45:28 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-06-27 14:45:29 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from IPython.display import Audio, display\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from omegaconf import OmegaConf\n",
    "from nemo.utils.exp_manager import exp_manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e2e3b-2323-4a20-aa69-cd2562d80ee6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get Data for Speaker Net to be Fine-Tuned on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4512f2d-70d3-4858-b61e-89e071fd2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NEMO_ROOT = os.getcwd()\n",
    "print(NEMO_ROOT)\n",
    "import glob\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "\n",
    "data_dir = os.path.join(NEMO_ROOT,'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Download the dataset. This will take a few moments...\n",
    "print(\"******\")\n",
    "if not os.path.exists(data_dir + '/an4_sphere.tar.gz'):\n",
    "    an4_url = 'https://dldata-public.s3.us-east-2.amazonaws.com/an4_sphere.tar.gz'  # for the original source, please visit http://www.speech.cs.cmu.edu/databases/an4/an4_sphere.tar.gz \n",
    "    an4_path = wget.download(an4_url, data_dir)\n",
    "    print(f\"Dataset downloaded at: {an4_path}\")\n",
    "else:\n",
    "    print(\"Tarfile already exists.\")\n",
    "    an4_path = data_dir + '/an4_sphere.tar.gz'\n",
    "\n",
    "# Untar and convert .sph to .wav (using sox)\n",
    "tar = tarfile.open(an4_path)\n",
    "tar.extractall(path=data_dir)\n",
    "\n",
    "print(\"Converting .sph to .wav...\")\n",
    "sph_list = glob.glob(data_dir + '/an4/**/*.sph', recursive=True)\n",
    "for sph_path in sph_list:\n",
    "    wav_path = sph_path[:-4] + '.wav'\n",
    "    cmd = [\"sox\", sph_path, wav_path]\n",
    "    subprocess.run(cmd)\n",
    "print(\"Finished conversion.\\n******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd85496-7414-47ee-a4a2-1585d323795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading necessary scripts\")\n",
    "!mkdir -p scripts/speaker_tasks\n",
    "!wget -P scripts/speaker_tasks/ https://raw.githubusercontent.com/NVIDIA/NeMo/main/scripts/speaker_tasks/filelist_to_manifest.py\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341bbde7-77cf-4d40-b240-366b346a7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "!find {data_dir}/an4/wav/an4test_clstk  -iname \"*.wav\" > {data_dir}/an4/wav/an4test_clstk/test_all.txt\n",
    "!python {NEMO_ROOT}/scripts/speaker_tasks/filelist_to_manifest.py --filelist {data_dir}/an4/wav/an4test_clstk/test_all.txt --id -2 --out {data_dir}/an4/wav/an4test_clstk/test.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5ec46-c1fd-46a5-884c-7fcebd372ab2",
   "metadata": {},
   "source": [
    "## Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e03d04-4f86-44b3-a5b7-a740f6af3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #speakernet base config\n",
    "# !mkdir -p conf\n",
    "!wget -P conf https://raw.githubusercontent.com/NVIDIA/NeMo/r1.19.0/examples/speaker_tasks/recognition/conf/ecapa_tdnn.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c9d5d5-17c2-4bc6-82d4-03eb37e422b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get speakernet config file\n",
    "MODEL_CONFIG = os.path.join('conf/ecapa_tdnn.yaml')\n",
    "finetune_config = OmegaConf.load(MODEL_CONFIG)\n",
    "# print(OmegaConf.to_yaml(finetune_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1add21b-481d-467c-bf93-70f0784a2f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Data Config (from data gathering above)\n",
    "# test_manifest = os.path.join(data_dir,'data/an4/wav/an4test_clstk/test.json')\n",
    "train_manifest = os.path.join('/Users/ajaybati/Documents/speakerNet/SpeakerNetTest/training/data/an4/wav/an4test_clstk/test.json')\n",
    "validation_manifest = os.path.join('/Users/ajaybati/Documents/speakerNet/SpeakerNetTest/training/data/an4/wav/an4test_clstk/test.json')\n",
    "finetune_config.model.train_ds.manifest_filepath = train_manifest\n",
    "finetune_config.model.validation_ds.manifest_filepath = validation_manifest\n",
    "finetune_config.model.train_ds.augmentor.noise.manifest_path = train_manifest\n",
    "finetune_config.model.decoder.num_classes = 10 #PLEASE CHANGE TO ACTUAL NUMBER OF CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7637e5cd-eaeb-4ee6-9f24-913ce4f7cfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2023-06-27 14:45:37 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pytorch_lightning/trainer/setup.py:201: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "#Trainer Config\n",
    "#parameters can be tweaked if necessary\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "trainer_config = OmegaConf.create(dict(\n",
    "    devices=1,\n",
    "    accelerator=accelerator,\n",
    "    max_epochs=5,\n",
    "    max_steps=-1,\n",
    "    num_nodes=1,\n",
    "    accumulate_grad_batches=1,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    "    log_every_n_steps=1,  #Interval of logging.\n",
    "    val_check_interval=1.0,  #Set to 0.25 to check 4 times per epoch, or an int for number of iterations\n",
    "))\n",
    "# print(OmegaConf.to_yaml(trainer_config))\n",
    "trainer_finetune = pl.Trainer(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd206928-3eb1-4d51-99f8-3ceaee22501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-27 14:45:38 collections:298] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:299] Dataset loaded with 130 items, total duration of  0.10 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:301] # 130 files loaded accounting to # 10 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-27 14:45:38 label_models:180] Total number of 10 found in all the manifest files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-27 14:45:38 collections:193] Dataset loaded with 130 files totalling 0.10 hours\n",
      "[NeMo I 2023-06-27 14:45:38 collections:194] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2023-06-27 14:45:38 collections:298] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:299] Dataset loaded with 130 items, total duration of  0.10 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:301] # 130 files loaded accounting to # 10 labels\n",
      "[NeMo I 2023-06-27 14:45:38 collections:298] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:299] Dataset loaded with 130 items, total duration of  0.10 hours.\n",
      "[NeMo I 2023-06-27 14:45:38 collections:301] # 130 files loaded accounting to # 10 labels\n",
      "[NeMo I 2023-06-27 14:45:38 features:289] PADDING: 16\n",
      "[NeMo I 2023-06-27 14:45:38 cloud:58] Found existing object /Users/ajaybati/.cache/torch/NeMo/NeMo_1.19.0rc0/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n",
      "[NeMo I 2023-06-27 14:45:38 cloud:64] Re-using file from: /Users/ajaybati/.cache/torch/NeMo/NeMo_1.19.0rc0/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo\n",
      "[NeMo I 2023-06-27 14:45:38 common:913] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-27 14:45:38 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2023-06-27 14:45:38 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-27 14:45:38 features:289] PADDING: 16\n",
      "[NeMo I 2023-06-27 14:45:39 save_restore_connector:249] Model EncDecSpeakerLabelModel was successfully restored from /Users/ajaybati/.cache/torch/NeMo/NeMo_1.19.0rc0/ecapa_tdnn/3e0c5c4731b176aeb70c29a74d800c81/ecapa_tdnn.nemo.\n",
      "[NeMo I 2023-06-27 14:45:39 modelPT:1136] Model checkpoint partially restored from pretrained checkpoint with name `ecapa_tdnn`\n",
      "[NeMo I 2023-06-27 14:45:39 modelPT:1138] The following parameters were excluded when loading from pretrained checkpoint with name `ecapa_tdnn` : ['decoder.final.weight']\n",
      "[NeMo I 2023-06-27 14:45:39 modelPT:1141] Make sure that this is what you wanted!\n"
     ]
    }
   ],
   "source": [
    "#load model (from pretrained speakerverification_speakernet, \n",
    "#but exclude decoder.final classification layer because now we have different number of speakers)\n",
    "speaker_model = nemo_asr.models.EncDecSpeakerLabelModel(cfg=finetune_config.model, trainer=trainer_finetune)\n",
    "speaker_model.maybe_init_from_pretrained_checkpoint(finetune_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b69245-73fa-442f-ab83-1ab83eca9238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-27 14:45:39 exp_manager:374] Experiments will be logged at /Users/ajaybati/Documents/speakerNet/SpeakerNetTest/training/nemo_experiments/ECAPA_TDNN/2023-06-27_14-45-39\n",
      "[NeMo I 2023-06-27 14:45:39 exp_manager:797] TensorboardLogger has been set up\n",
      "[NeMo I 2023-06-27 14:45:39 exp_manager:912] Preemption is supported only on GPUs, disabling preemption\n",
      "/Users/ajaybati/Documents/speakerNet/SpeakerNetTest/training/nemo_experiments/ECAPA_TDNN/2023-06-27_14-45-39\n"
     ]
    }
   ],
   "source": [
    "from nemo.utils.exp_manager import exp_manager\n",
    "log_dir = exp_manager(trainer_finetune, finetune_config.get(\"exp_manager\", None))\n",
    "# The log_dir provides a path to the current logging directory for easy access\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9c7668-7b99-43b1-aaf0-ca1421ca26f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resampy\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6ebf4b-b820-494b-80a0-d34bc8074981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-27 14:45:56 modelPT:721] Optimizer config = SGD (\n",
      "    Parameter Group 0\n",
      "        dampening: 0\n",
      "        differentiable: False\n",
      "        foreach: None\n",
      "        lr: 0.08\n",
      "        maximize: False\n",
      "        momentum: 0\n",
      "        nesterov: False\n",
      "        weight_decay: 0.0002\n",
      "    )\n",
      "[NeMo I 2023-06-27 14:45:56 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x174ca3ac0>\" \n",
      "    will be used during training (effective maximum steps = 15) - \n",
      "    Parameters : \n",
      "    (warmup_ratio: 0.1\n",
      "    min_lr: 0.0001\n",
      "    max_steps: 15\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | loss              | AngularSoftmaxLoss                | 0     \n",
      "1 | eval_loss         | AngularSoftmaxLoss                | 0     \n",
      "2 | _accuracy         | TopKClassificationAccuracy        | 0     \n",
      "3 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "4 | encoder           | ECAPAEncoder                      | 18.1 M\n",
      "5 | decoder           | SpeakerDecoder                    | 2.8 M \n",
      "6 | _macro_accuracy   | MulticlassAccuracy                | 0     \n",
      "7 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "------------------------------------------------------------------------\n",
      "20.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.9 M    Total params\n",
      "83.675    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-27 14:45:56 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2023-06-27 14:48:56 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "      rank_zero_warn(\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01e114786484d3a914190689a16fee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-27 14:50:35 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2023-06-27 14:51:12 nemo_logging:349] /Users/ajaybati/miniconda3/envs/sanas/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "      rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "trainer_finetune.fit(speaker_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d22df-f0d9-4a0b-88cb-44f828fdb8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
